- name: Tests
  hosts: localhost
  connection: local
  collections:
  - kubernetes.core
  vars:
    custom_resource: "{{ lookup('template', cr_file_path) | from_yaml }}"
  tasks:

  # the first kiali install is coming online - it has the default instance_name of 'kiali'
  - import_tasks: ../common/tasks.yml
  - import_tasks: ../asserts/pod_asserts.yml
  - import_tasks: ../asserts/accessible_namespaces_contains.yml
    vars:
      namespace_list: [ 'instancenametest' ]

  # TODO the k8s lookup below assumes faulty behavior - may need to change in the future. See: https://github.com/ansible-collections/kubernetes.core/issues/147
  - name: Make sure the one new namespace label exists
    vars:
      namespacesWithLabel: "{{ lookup('kubernetes.core.k8s', kind='Namespace', label_selector='kiali.io/member-of=' + istio.control_plane_namespace) }}"
    assert:
      that:
      - namespacesWithLabel | selectattr('metadata.name', 'equalto', 'instancenametest') | length == 1

  # now install a second kiali with the instance_name of 'kialitwo' and wait for it to come online
  - set_fact:
      kiali: "{{ kiali | combine({'instance_name': 'kialitwo'}, recursive=True) }}"
  - set_fact:
      custom_resource: "{{ lookup('template', cr_file_path) | from_yaml }}"

  - debug:
      msg: "INSTALL KIALITWO"

  - import_tasks: ../common/set_kiali_cr.yml
    vars:
      new_kiali_cr: "{{ custom_resource }}"
  - import_tasks: ../common/wait_for_kiali_cr_changes.yml
  - import_tasks: ../common/wait_for_kiali_running.yml
  - import_tasks: ../common/tasks.yml
  - import_tasks: ../asserts/pod_asserts.yml

  # TODO the k8s lookup below assumes faulty behavior - may need to change in the future. See: https://github.com/ansible-collections/kubernetes.core/issues/147
  - name: Make sure the two new namespace labels exists and the two labels on the signing key exist
    vars:
      namespacesWithLabel1: "{{ lookup('kubernetes.core.k8s', kind='Namespace', label_selector='kiali.io/member-of=' + istio.control_plane_namespace) }}"
      namespacesWithLabel2: "{{ lookup('kubernetes.core.k8s', kind='Namespace', label_selector='kiali.io/kialitwo.member-of=' + istio.control_plane_namespace) }}"
      signingKeyWithLabel1: "{{ lookup('kubernetes.core.k8s', kind='Secret',    label_selector='kiali.io/member-of=' + istio.control_plane_namespace) }}"
      signingKeyWithLabel2: "{{ lookup('kubernetes.core.k8s', kind='Secret',    label_selector='kiali.io/kialitwo.member-of=' + istio.control_plane_namespace) }}"
    assert:
      that:
      - namespacesWithLabel1 | selectattr('metadata.name', 'equalto', 'instancenametest') | length == 1
      - namespacesWithLabel2 | selectattr('metadata.name', 'equalto', 'instancenametest') | length == 1
      - signingKeyWithLabel1 | selectattr('metadata.name', 'equalto', 'kiali-signing-key') | length == 1
      - signingKeyWithLabel2 | selectattr('metadata.name', 'equalto', 'kiali-signing-key') | length == 1

  # TODO the k8s lookup below assumes faulty behavior - may need to change in the future. See: https://github.com/ansible-collections/kubernetes.core/issues/147
  # just set some common constants so our assert code below is easier to read
  - set_fact:
      queryNamespace: "{{ istio.control_plane_namespace }}"
      apiCMap: "v1"
      apiDepl: "apps/v1"
      apiRole: "rbac.authorization.k8s.io/v1"
      apiRoBi: "rbac.authorization.k8s.io/v1"
      apiServ: "v1"
      apiSvcA: "v1"
      apiIngr: "networking.k8s.io/{{ 'v1' if (lookup('kubernetes.core.k8s', kind='Ingress', api_version='networking.k8s.io/v1', errors='ignore') is iterable) else 'v1beta1' }}"
      apiRout: "route.openshift.io/v1"

  # TODO This confirms the behavior that we expect but is likely faulty.
  # If this assert fails, it means https://github.com/ansible-collections/kubernetes.core/issues/147 was fixed
  # and that we need to check all calls to lookup and query using kubernetes.core.k8s and make sure they still work as intended.
  - assert:
      that:
      - lookup('kubernetes.core.k8s', kind='Ingress', api_version='networking.k8s.io/v1', errors='ignore') is iterable
      - lookup('kubernetes.core.k8s', kind='Ingress', api_version='networking.k8s.io/v1_INVALID', errors='ignore') is not iterable

  # TODO the k8s lookup below assumes faulty behavior - may need to change in the future. See: https://github.com/ansible-collections/kubernetes.core/issues/147
  - name: Kubernetes - Make sure we have the basic resources we expect, with the labels we expect
    assert:
      that:
      - lookup('kubernetes.core.k8s', kind='ConfigMap',      namespace=queryNamespace, api_version=apiCMap, label_selector=item) | length == 1
      - lookup('kubernetes.core.k8s', kind='Deployment',     namespace=queryNamespace, api_version=apiDepl, label_selector=item) | length == 1
      - lookup('kubernetes.core.k8s', kind='Role',           namespace=queryNamespace, api_version=apiRole, label_selector=item) | length == 2
      - lookup('kubernetes.core.k8s', kind='RoleBinding',    namespace=queryNamespace, api_version=apiRoBi, label_selector=item) | length == 2
      - lookup('kubernetes.core.k8s', kind='Service',        namespace=queryNamespace, api_version=apiServ, label_selector=item) | length == 1
      - lookup('kubernetes.core.k8s', kind='ServiceAccount', namespace=queryNamespace, api_version=apiSvcA, label_selector=item) | length == 1
      - lookup('kubernetes.core.k8s', kind='Ingress',        namespace=queryNamespace, api_version=apiIngr, label_selector=item) | length == 1
    loop:
    - app.kubernetes.io/instance=kiali
    - app.kubernetes.io/instance=kialitwo
    when:
    - is_k8s == True

  # TODO the k8s lookup below assumes faulty behavior - may need to change in the future. See: https://github.com/ansible-collections/kubernetes.core/issues/147
  - name: OpenShift - Make sure we have the basic resources we expect, with the labels we expect
    assert:
      that:
      - lookup('kubernetes.core.k8s', kind='ConfigMap',      namespace=queryNamespace, api_version=apiCMap, label_selector=item) | length == 2
      - lookup('kubernetes.core.k8s', kind='Deployment',     namespace=queryNamespace, api_version=apiDepl, label_selector=item) | length == 1
      - lookup('kubernetes.core.k8s', kind='Role',           namespace=queryNamespace, api_version=apiRole, label_selector=item) | length == 2
      - lookup('kubernetes.core.k8s', kind='RoleBinding',    namespace=queryNamespace, api_version=apiRoBi, label_selector=item) | length == 2
      - lookup('kubernetes.core.k8s', kind='Service',        namespace=queryNamespace, api_version=apiServ, label_selector=item) | length == 1
      - lookup('kubernetes.core.k8s', kind='ServiceAccount', namespace=queryNamespace, api_version=apiSvcA, label_selector=item) | length == 1
      - lookup('kubernetes.core.k8s', kind='Route',          namespace=queryNamespace, api_version=apiRout, label_selector=item) | length == 1
    loop:
    - app.kubernetes.io/instance=kiali
    - app.kubernetes.io/instance=kialitwo
    when:
    - is_openshift == True

  # now delete the second kiali (the one with the instance_name of 'kialitwo') and see that things get cleaned up
  - debug:
      msg: "DELETE KIALITWO"

  - name: Deleting kialitwo instance
    k8s:
      state: absent
      wait: yes
      wait_sleep: 5
      wait_timeout: "{{ 5 * wait_retries|int }}"
      api_version: kiali.io/v1alpha1
      kind: Kiali
      name: "{{ custom_resource.metadata.name }}"
      namespace: "{{ cr_namespace }}"

  # TODO the k8s lookup below assumes faulty behavior - may need to change in the future. See: https://github.com/ansible-collections/kubernetes.core/issues/147
  - name: Make sure the first namespace label exists but the second one is gone, same with the signing key
    vars:
      namespacesWithLabel1: "{{ lookup('kubernetes.core.k8s', kind='Namespace', label_selector='kiali.io/member-of=' + istio.control_plane_namespace) }}"
      namespacesWithLabel2: "{{ lookup('kubernetes.core.k8s', kind='Namespace', label_selector='kiali.io/kialitwo.member-of=' + istio.control_plane_namespace) }}"
      signingKeyWithLabel1: "{{ lookup('kubernetes.core.k8s', kind='Secret',    label_selector='kiali.io/member-of=' + istio.control_plane_namespace) }}"
      signingKeyWithLabel2: "{{ lookup('kubernetes.core.k8s', kind='Secret',    label_selector='kiali.io/kialitwo.member-of=' + istio.control_plane_namespace) }}"
    assert:
      that:
      - namespacesWithLabel1 | selectattr('metadata.name', 'equalto', 'instancenametest') | length == 1
      - namespacesWithLabel2 | selectattr('metadata.name', 'equalto', 'instancenametest') | length == 0
      - signingKeyWithLabel1 | selectattr('metadata.name', 'equalto', 'kiali-signing-key') | length == 1
      - signingKeyWithLabel2 | selectattr('metadata.name', 'equalto', 'kiali-signing-key') | length == 0

  # Check that the resources for the remaining instance still exist

  # TODO the k8s lookup below assumes faulty behavior - may need to change in the future. See: https://github.com/ansible-collections/kubernetes.core/issues/147
  - name: Kubernetes - Make sure we have the basic resources we expect, with the labels we expect for the remaining instance
    assert:
      that:
      - lookup('kubernetes.core.k8s', kind='ConfigMap',      namespace=queryNamespace, api_version=apiCMap, label_selector=item) | length == 1
      - lookup('kubernetes.core.k8s', kind='Deployment',     namespace=queryNamespace, api_version=apiDepl, label_selector=item) | length == 1
      - lookup('kubernetes.core.k8s', kind='Role',           namespace=queryNamespace, api_version=apiRole, label_selector=item) | length == 2
      - lookup('kubernetes.core.k8s', kind='RoleBinding',    namespace=queryNamespace, api_version=apiRoBi, label_selector=item) | length == 2
      - lookup('kubernetes.core.k8s', kind='Service',        namespace=queryNamespace, api_version=apiServ, label_selector=item) | length == 1
      - lookup('kubernetes.core.k8s', kind='ServiceAccount', namespace=queryNamespace, api_version=apiSvcA, label_selector=item) | length == 1
      - lookup('kubernetes.core.k8s', kind='Ingress',        namespace=queryNamespace, api_version=apiIngr, label_selector=item) | length == 1
    loop:
    - app.kubernetes.io/instance=kiali
    when:
    - is_k8s == True

  # TODO the k8s lookup below assumes faulty behavior - may need to change in the future. See: https://github.com/ansible-collections/kubernetes.core/issues/147
  - name: OpenShift - Make sure we have the basic resources we expect, with the labels we expect for the remaining instance
    assert:
      that:
      - lookup('kubernetes.core.k8s', kind='ConfigMap',      namespace=queryNamespace, api_version=apiCMap, label_selector=item) | length == 2
      - lookup('kubernetes.core.k8s', kind='Deployment',     namespace=queryNamespace, api_version=apiDepl, label_selector=item) | length == 1
      - lookup('kubernetes.core.k8s', kind='Role',           namespace=queryNamespace, api_version=apiRole, label_selector=item) | length == 2
      - lookup('kubernetes.core.k8s', kind='RoleBinding',    namespace=queryNamespace, api_version=apiRoBi, label_selector=item) | length == 2
      - lookup('kubernetes.core.k8s', kind='Service',        namespace=queryNamespace, api_version=apiServ, label_selector=item) | length == 1
      - lookup('kubernetes.core.k8s', kind='ServiceAccount', namespace=queryNamespace, api_version=apiSvcA, label_selector=item) | length == 1
      - lookup('kubernetes.core.k8s', kind='Route',          namespace=queryNamespace, api_version=apiRout, label_selector=item) | length == 1
    loop:
    - app.kubernetes.io/instance=kiali
    when:
    - is_openshift == True

  # Check that the resources for the deleted instance have been removed

  # TODO the k8s lookup below assumes faulty behavior - may need to change in the future. See: https://github.com/ansible-collections/kubernetes.core/issues/147
  - name: Kubernetes - Confirm we have no more resources for the deleted instance
    assert:
      that:
      - lookup('kubernetes.core.k8s', kind='ConfigMap',      namespace=queryNamespace, api_version=apiCMap, label_selector=item) | length == 0
      - lookup('kubernetes.core.k8s', kind='Deployment',     namespace=queryNamespace, api_version=apiDepl, label_selector=item) | length == 0
      - lookup('kubernetes.core.k8s', kind='Role',           namespace=queryNamespace, api_version=apiRole, label_selector=item) | length == 0
      - lookup('kubernetes.core.k8s', kind='RoleBinding',    namespace=queryNamespace, api_version=apiRoBi, label_selector=item) | length == 0
      - lookup('kubernetes.core.k8s', kind='Service',        namespace=queryNamespace, api_version=apiServ, label_selector=item) | length == 0
      - lookup('kubernetes.core.k8s', kind='ServiceAccount', namespace=queryNamespace, api_version=apiSvcA, label_selector=item) | length == 0
      - lookup('kubernetes.core.k8s', kind='Ingress',        namespace=queryNamespace, api_version=apiIngr, label_selector=item) | length == 0
    loop:
    - app.kubernetes.io/instance=kialitwo
    when:
    - is_k8s == True

  # TODO the k8s lookup below assumes faulty behavior - may need to change in the future. See: https://github.com/ansible-collections/kubernetes.core/issues/147
  - name: OpenShift - Confirm we have no more resources for the deleted instance
    assert:
      that:
      - lookup('kubernetes.core.k8s', kind='ConfigMap',      namespace=queryNamespace, api_version=apiCMap, label_selector=item) | length == 0
      - lookup('kubernetes.core.k8s', kind='Deployment',     namespace=queryNamespace, api_version=apiDepl, label_selector=item) | length == 0
      - lookup('kubernetes.core.k8s', kind='Role',           namespace=queryNamespace, api_version=apiRole, label_selector=item) | length == 0
      - lookup('kubernetes.core.k8s', kind='RoleBinding',    namespace=queryNamespace, api_version=apiRoBi, label_selector=item) | length == 0
      - lookup('kubernetes.core.k8s', kind='Service',        namespace=queryNamespace, api_version=apiServ, label_selector=item) | length == 0
      - lookup('kubernetes.core.k8s', kind='ServiceAccount', namespace=queryNamespace, api_version=apiSvcA, label_selector=item) | length == 0
      - lookup('kubernetes.core.k8s', kind='Route',          namespace=queryNamespace, api_version=apiRout, label_selector=item) | length == 0
    loop:
    - app.kubernetes.io/instance=kialitwo
    when:
    - is_openshift == True

